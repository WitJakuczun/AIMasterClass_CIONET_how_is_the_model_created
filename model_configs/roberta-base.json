{
    "model_path": "models/roberta",
    "model_name": "roberta-base",
    "training_arguments": {
        "num_train_epochs": 1,
        "per_device_train_batch_size": 8,
        "gradient_accumulation_steps": 1,
        "learning_rate": 2e-5,
        "logging_steps": 10
    }
}